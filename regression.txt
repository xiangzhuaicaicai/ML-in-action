import numpy as np
from time import sleep
import json
import urllib3


def loadDataSet(fileName):
    """
    此数据集三个为一组两个特征，一个目标值,假定X0都是一
    :param fileName:
    :return:
            X0=1
    """
    numFeat = len(open(fileName).readline().split('\t')) - 1
    dataMat = []; labelMat = []
    fr =open(fileName)
    for line in fr.readlines():
        lineArr = []
        curLine = line.strip().split('\t')
        for i in range(numFeat):
            lineArr.append(float(curLine[i]))
        dataMat.append(lineArr)
        labelMat.append(float(curLine[-1]))
    return dataMat, labelMat


def standRegres(xArr, yArr):
    """
    计算并返回回归系数
    :param xArr: 特征矩阵
    :param yArr: 目标值
    :return:
            ws-回归系数
    """
    xMat = np.mat(xArr); yMat = np.mat(yArr).T
    xTx = xMat.T * xMat
    if np.linalg.det(xTx) == 0.0:                           #计算矩阵的行列式,矩阵存在逆的充要条件是行列式不等于0
        print('this matrix is singular, cannot do inverse')
        return
    ws = xTx.I * (xMat.T*yMat)                           #xTx.I求矩阵的逆
    return ws

'''
def show(x,y,ws):
    """
    画出图形
    :param x:数据集的特征向量
    :param y:数据集的标签
    :param ws:回归系数
    :return:

    """
    import matplotlib.pyplot as plt
    xMat = np.mat(x); yMat = np.mat(y)
    fig = plt.figure()
    ax = fig.add_subplot(111)
    ax.scatter(xMat[:,1].flatten().A[0], yMat.T[:,0].flatten().A[0])   #flatten把矩阵整合成一列矩阵
    xCopy = xMat.copy(); xCopy.sort(0)                                 #把xMat从小到大排列/‘
    yHat = xCopy * ws
    ax.plot(xCopy[:,1], yHat)
    plt.show()
'''

def lwlr(testPoint, xArr, yArr, k=1.0):
    """

    :param testPoint: 测试样本点
    :param xArr: 特征向量
    :param yArr: 标签向量
    :param k: 衰减参数
    :return:
            预测值
    """
    xMat = np.mat(xArr); yMat = np.mat(yArr).T
    m = np.shape(xMat)[0]                                           #样本点个数
    weights = np.mat(np.eye((m)))                                      #构建对角权重矩阵,阶数为样本点个数,为每个样本点初始化一个权重
    for j in range(m):
        diffMat = testPoint - xMat[j,:]                          #计算样本点与待预测点的距离diffMat
        weights[j,j] = np.exp(diffMat*diffMat.T / (-2.0 * k**2))    #diffMat增加，权重以指数形式衰减,k控制衰减速度
    xTx = xMat.T * (weights * xMat)
    if np.linalg.det(xTx) == 0.0:
        print('this matrix in singular, cannot do inverse')
        return
    ws = xTx.I * (xMat.T * (weights * yMat))
    return testPoint * ws


def lwlrTest(testArr, xArr, yArr, k=1.0):
    """

    :param testArr: 测试样本点
    :param xArr: 特征向量
    :param yArr: 标签向量
    :param k: 衰减参数
    :return:
            yHat-预测值
    """
    m = np.shape(testArr)[0]
    yHat = np.zeros(m)
    for i in range(m):
        yHat[i] = lwlr(testArr[i], xArr, yArr, k)
    return yHat


def rssError(yArr,yHatArr):
    """

    :param yArr: 真实值
    :param yHatArr: 预测值
    :return:
            误差平方和
    """
    return ((yArr-yHatArr)**2).sum()


def ridgeRegres(xMat, yMat, lam=2):
    """

    :param xMat: 特征向量
    :param yMat: 标签
    :param lam: lambda惩罚系数
    :return:
            回归系数
    """
    xTx = xMat.T*xMat
    denom = xTx + np.eye(np.shape(xMat)[1]) *lam
    if np.linalg.det(denom) == 0.0:
        print('this matrix is singular,cannot do inverse')
        return
    ws = denom.I * (xMat.T*yMat)
    return ws


def ridgeTest(xArr, yArr):
    """

    :param xArr: 特征向量
    :param yArr: 标签
    :return:
            回归系数矩阵
    """
    xMat = np.mat(xArr); yMat = np.mat(yArr).T
    yMean = np.mean(yMat, 0)
    yMat = yMat - yMean                                             #数据标准化，使每维特征具有相同的重要性
    xMeans = np.mean(xMat, 0)                                       #数据标准化的方法，所有特征减去各自的均值除以方差
    xVar = np.var(xMat, 0)                                          #方差
    xMat = (xMat - xMeans) / xVar
    numberTestPts = 30
    wMat = np.zeros((numberTestPts,np.shape(xMat)[1]))              #回归系数矩阵，个数为lambda的个数
    for i in range(numberTestPts):
        ws = ridgeRegres(xMat, yMat, np.exp(i-10))                  #lambda以指数级变化
        wMat[i:] = ws.T
    return wMat


#书上没有这一段
def regularize(xMat):
    """
    function:把特征向量正则化
    :param xMat:
    :return:
    """
    inMat = xMat.copy()
    imMeans = np.mean(inMat,0)                 #按列平均
    inVar = np.var(inMat, 0)                   #var（X)与var(X,0)相同
    inMat = (inMat - imMeans) / inVar
    return inMat


def stageWise(xArr, yArr, eps=0.01, numIt=100):
    """

    :param xArr: 输入数据
    :param yArr: 预测变量
    :param eps: 每次迭代需要调整的步长
    :param numIt: 迭代次数
    :return:
            回归系数矩阵
    """
    xMat = np.mat(xArr); yMat = np.mat(yArr).T                             #将输入数据转换并存到矩阵中
    yMean = np.mean(yMat, 0)                                               #按列平均
    yMat = yMat - yMean                                                    #正则化
    xMat = regularize(xMat)                                                #正则化
    m, n = np.shape(xMat)
    returnMat = np.zeros((numIt,n))                                        #回归系数矩阵
    ws = np.zeros((n,1)); wsTest = ws.copy(); wsMax = ws.copy()
    for i in range(numIt):
        print(ws.T)
        lowestError = np.inf                                               #初始化误差为正无穷
        for j in range(n):                                                 #对每个特征
            for sign in [-1,1]:                                            #两次循环，计算增加或者减少该特征对误差的影响
                wsTest = ws.copy()
                wsTest[j] += eps * sign
                yTest = xMat * wsTest
                rssE = rssError(yMat.A, yTest.A)                           #平方误差和
                if rssE < lowestError:                                     #当前的误差小于上一次的话，交换
                    lowestError = rssE
                    wsMax = wsTest
        ws = wsMax.copy()
        returnMat[i,:] = ws.T
    return returnMat


#由于书上的那个API失效了  所以剩下的代码就不敲了